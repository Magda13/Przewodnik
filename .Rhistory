??"eurostat"
install.packages("eurostat")
install.packages("eurostat")
library("eurostat")
dat <- get_eurostat("nama_nace31_k")
sample<-subset(dat, indic_na == "B1G" & unit == "PCH_PRE" & nace_r1 == "D" & geo == "FI")
summary(sample$values)
library(archivist)
exampleRepoDir <- tempdir()
?copyGithubRepo
exampleRepoDir <- tempdir()
hashes <- searchInGithubRepo( pattern="name", user="pbiecek", repo="archivist", fixed=FALSE )
createEmptyRepo( exampleRepoDir )
copyGithubRepo( repoTo = exampleRepoDir , md5hashes= hashes, user="pbiecek", repo="archivist" )
# removing an example Repository
deleteRepo( exampleRepoDir )
rm( exampleRepoDir )
# many archivist-like Repositories on one Github repository
dir <- paste0(getwd(), "/ex1")
createEmptyRepo( dir )
copyGithubRepo(repoTo = dir , md5hashes = "ff575c261c949d073b2895b05d1097c3",
user="MarcinKosinski", repo="Museum",
branch="master", repoDirGit="ex2")
deleteRepo( dir , TRUE)
dir
list.files()
checkDirectory
archivist:::checkDirectory
archivist:::aoptions()
archivist:::aoptions
?aoptions
checkDirectory
archivist::checkDirectory
archivist:::checkDirectory
aoptions
?assign
50*8*20
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "3ZNPRjfM0xzB38bdvmqzgFNYU"
consumerSecret <- "t6u74oLeLcRPImYGcXX5Y3EIXpEsr9bryrvO8WjQIjOwoHsJnr"
access_token="3091082482-kE4nw7fehbN7sL9N19KFs97kAThJjjrdAag6D0m"
access_secret="xJaUa5AmfkNyBY77EM40TWoCzLZ790DmQlaaEasK2qfVs"
setup_twitter_oauth(consumerKey, consumerSecret, access_token, access_secret)
library(twitteR)
setup_twitter_oauth(consumerKey, consumerSecret, access_token, access_secret)
tweets <- searchTwitter("lis", n=1000)
dflis <- twListToDF(tweets)
summary(dflis$created)
head(dflis$text)
head(dflis$text,40)
head(dflis$text,400)
tweets <- searchTwitter("lis_tomasz", n=1000)
dflis <- twListToDF(tweets)
summary(dflis$created)
summary(dflis$text)
head(dflis$text)
tweets <- searchTwitter("lis_tomasz", n=2000)
dflis <- twListToDF(tweets)
head(dflis$text)
summary(dflis$created)
ggplot(dflis[dflis$created > "2015-10-19 19:30:00",], aes(x=created)) +
geom_histogram(bin=60)
library(ggplot2)
ggplot(dflis[dflis$created > "2015-10-19 19:30:00",], aes(x=created)) +
geom_histogram(bin=60)
ggplot(dflis, aes(x=created)) +
geom_histogram(bin=60)
dim(dflis)
tail(sort(table(dflis$text)))
tail(sort(table(dflis$text)), 30)
tweets2 <- searchTwitter("lis debata", n=2000)
dflis2 <- twListToDF(tweets2)
summary(dflis2$created)
library(SmarterPoland)
getBDLsearch() -> aa
getBDLsearch("bezrobocie") -> aa
head(aa)
getBDLseries(metric_id = 60, time_range= '2010:2010', gmina_id = '1') -> gg
library(devtools)
install_github("pbiecek/SmarterPoland")
library(SmarterPoland)
getBDLseries(metric_id = 60, time_range= '2010:2010', gmina_id = '1') -> gg
getBDLseries
install_github("pbiecek/SmarterPoland")
getBDLseries
getBDLseries(metric_id = 60, time_range= '2010:2010', gmina_id = '1') -> gg
metric_id = 60; time_range= '2010:2010'; gmina_id = '1'
url0 <- 'https://api-v3.mojepanstwo.pl/dane/bdl_wskazniki?limit=500&page='
result <- getAllPages(url0, debug=debug)
url <- paste0("https://api-v3.mojepanstwo.pl/bdl/series?metric_id=",
metric_id)
url <- paste0(url, "&time_range=", htmlEscape(time_range))
url <- paste0(url, "&gmina_id=", htmlEscape(gmina_id))
document <- jsonlite::fromJSON(txt = url,
simplifyDataFrame=FALSE)
met <- t(sapply(document$slices, function(s) s$slice))
met
str(document)
names(document)
url
library(devtools)
install_github("BetaAndBit/PieczaraPietraszki/proton")
library(proton)
proton
proton(wskazowka=T)
proton(action="login", login="janie", wskazowka=T)
proton(action="login", login="janie", password="q1w2e3r4t5", wskazowka=T)
proton(action="server", host="194.29.178.16", wskazowka=T)
proton(action="login", login="slap", password="DHbb7QXppuHnaXGN")
library(RTCGA.PANCAN12)
expression <- rbind(expression.cb1, expression.cb2)
sel <- expression[expression$Sample == "MDM2",-1]
tylkoMDM2 <- unlist(expression[expression$Sample == "MDM2",-1])
clinical.cb$sampleID <- gsub(as.character(clinical.cb$sampleID), pattern = "-", replacement = ".")
clinicalBRCA <- na.omit(clinical.cb[clinical.cb$X_cohort == "TCGA Breast Cancer",c("sampleID", "X_cohort","X_TIME_TO_EVENT","X_EVENT")])
tylkoTP53 <- mutation.cb[which(mutation.cb$Sample == "TP53"),-1]
dfT <- data.frame(sampleID = names(tylkoTP53), value = t(tylkoTP53))
dfcliT <- merge(dfT, clinicalBRCA)
dfM <- data.frame(sampleID = names(tylkoMDM2), value = tylkoMDM2)
dfcliM <- merge(dfM, dfcliT)
library(survival)
library(survMisc)
survMisc::autoplot(survfit(Surv(X_TIME_TO_EVENT,X_EVENT)~X18475+(value>=0), data=dfcliM))$plot + ylim(0,1) + xlim(0,3000)
library(ggplot2)
library(survival)
library(survMisc)
survMisc::autoplot(survfit(Surv(X_TIME_TO_EVENT,X_EVENT)~X18475+(value>=0), data=dfcliM))$plot + ylim(0,1) + xlim(0,3000)
survMisc::autoplot(survfit(Surv(X_TIME_TO_EVENT,X_EVENT)~X18475+(value>=0)==2, data=dfcliM))$plot + ylim(0,1) + xlim(0,3000)
survdiff(Surv(X_TIME_TO_EVENT,X_EVENT)~(X18475+(value>=0)==2), data=dfcliM)
survdiff(Surv(X_TIME_TO_EVENT,X_EVENT)~(X18475+(value>0)==2), data=dfcliM)
mean(dfcliM$value)
median(dfcliM$value)
survdiff(Surv(X_TIME_TO_EVENT,X_EVENT)~(X18475+(value>0.01)==2), data=dfcliM)
survdiff(Surv(X_TIME_TO_EVENT,X_EVENT)~(X18475+(value>=0.01)==2), data=dfcliM)
mean(dfcliM$value)
median(dfcliM$value)
1100/75
100/75
library(e1071)
?skewness
data("iris")
skewness(iris$Petal.Width, type=1)
sapply(1:3, skewness, x=iris$Petal.Width, na.rm=T)
sapply(1:3, kurtosis, x=iris$Petal.Width, na.rm=T)
?quantile
sapply(1:9, quantile, x=iris$Petal.Width, probs=0.01, na.rm=T, names=T)
sapply(1:9, quantile, x=iris$Petal.Width, probs=0.001, na.rm=T, names=T)
sapply(1:9, function(q) quantile(iris$Petal.Width, 0.01, type=q))
sapply(1:9, function(q) quantile(iris$Sepal.Length, 0.01, type=q))
sapply(1:9, function(q) quantile(iris$Sepal.Width, 0.01, type=q))
sapply(1:9, function(q) quantile(iris$Sepal.Length, 0.001, type=q))
sapply(1:9, function(q) quantile(iris$Sepal.Length, 0.01, type=q))
x <- runif(10)
sapply(1:9, function(q) quantile(x, 0.01, type=q))
x <- runif(101)
sapply(1:9, function(q) quantile(x, 0.01, type=q))
sapply(1:9, function(q) quantile(x, 0.01, type=q))
sapply(1:3, skewness, x=x, na.rm=T)
sapply(1:3, kurtosis, x=x, na.rm=T)
quantile()
quantile
quantile.default
stats:::quantile.default
methods(quantiles)
methods(quantile)
lm(Sepal.Width~Species, data=iris)
lm(Sepal.Width~Species, data=iris)$coef
lm(Sepal.Width~Species, data=iris, contrasts = contr.SAS)$coef
lm(Sepal.Width~Species, data=iris, contrasts = list(Species=contr.SAS))$coef
contr.SAS(3)
contr.helmert(3)
contr.treatment(3)
install.packages("knitcitations")
library(proton)
table(sapply(strsplit(bash_history, split=" "), `[`, 1))
proton(action="login", login="slap", password="DHbb7QXppuHnaXGN")
library(devtools)session_info()
library(devtools)session_info()
library(devtools)
session_info()
library(archivist)
?Tags
showLocalRepo(repoDir = repo, method = "tags")summaryLocalRepo(repoDir = system.file("graphGallery", package = "archivist"))
repo <- "new_repo"
createEmptyRepo(repoDir = repo)
copyGithubRepo( repoTo = repo, md5hashes= "2166dfbd3a7a68a91a2f8e6df1a44111",                 user="pbiecek", repo="graphGallery" )
copyGithubRepo( repoTo = repo, md5hashes= "2166dfbd3a7a68a91a2f8e6df1a44111",
user="pbiecek", repo="graphGallery" )
showLocalRepo(repoDir = repo, method = "tags")
summaryLocalRepo(repoDir = system.file("graphGallery", package = "archivist"))
showLocalRepo(repoDir = repo, method = "tags")
showLocalRepo(repoDir = repo)
shiny::runApp('Dropbox/_Prezentacje_I_Szkolenia_/2015 Politechnika Slaska Gliwice/3_interaktywne_aplikacje_shiny/shiny1')
shiny::runApp('Dropbox/_Prezentacje_I_Szkolenia_/2015 Politechnika Slaska Gliwice/3_interaktywne_aplikacje_shiny/shiny2')
shiny::runApp('Dropbox/_Prezentacje_I_Szkolenia_/2015 Politechnika Slaska Gliwice/3_interaktywne_aplikacje_shiny/shiny3')
library(archivist)
library(gamair)
install.packages("gamair")
library(gamair)
data(wine)
htestcor <- cor.test(wine$year, wine$s.temp, method = "pearson")
exampleRepoDir <- tempfile()
createEmptyRepo( repoDir = exampleRepoDir, default = TRUE )
htestcorMd5hash <- saveToRepo( htestcor )
htestcor
htestcorMd5hash <- saveToRepo( htestcor )
traceback()
options(error=recover)
htestcorMd5hash <- saveToRepo( htestcor )
query
sQuote("'")
library(proton)
table(sapply(strsplit(bash_history, split=" "), `[`, 1))
str(sleepstudy)
require(lattice)
xyplot(Reaction ~ Days | Subject, sleepstudy, type = c("g","p","r"),
index = function(x,y) coef(lm(y ~ x))[1],
xlab = "Days of sleep deprivation",
ylab = "Average reaction time (ms)", aspect = "xy")
library(lme4)
str(sleepstudy)
require(lattice)
xyplot(Reaction ~ Days | Subject, sleepstudy, type = c("g","p","r"),
index = function(x,y) coef(lm(y ~ x))[1],
xlab = "Days of sleep deprivation",
ylab = "Average reaction time (ms)", aspect = "xy")
readLines(url("https://cran.r-project.org/src/contrib/Archive/ggplot2/"))
library(XML)
readHTMLTable("https://cran.r-project.org/src/contrib/Archive/ggplot2/")
?readHTMLTable
tt <- getURL("https://cran.r-project.org/src/contrib/Archive/ggplot2/")
readHTMLTable(tt)
tt <- readLines(url("https://cran.r-project.org/src/contrib/Archive/ggplot2/"))
readHTMLTable(tt)
readHTMLTable(tt)[[1]]
readHTMLTable(tt)[[1]][,2]
readHTMLTable(tt)[[1]][,3]
as.character(readHTMLTable(tt)[[1]][,3])
library(lubridate)
dmy_hm(as.character(readHTMLTable(tt)[[1]][,3]))
tt <- readLines(url(paste0("https://cran.r-project.org/src/contrib/Archive/",pak)))
pak <- "ggplot2"
tt <- readLines(url(paste0("https://cran.r-project.org/src/contrib/Archive/",pak)))
dmy_hm(as.character(readHTMLTable(tt)[[1]][,3]))
data.frame(package=pak,
date=dmy_hm(as.character(readHTMLTable(tt)[[1]][,3])))
na.omit(data.frame(package=pak,
date=dmy_hm(as.character(readHTMLTable(tt)[[1]][,3]))))
tt <- readLines(url("https://cran.r-project.org/src/contrib/Archive/"))
readHTMLTable(tt)[[1]]
head(readHTMLTable(tt)[[1]])
packageList <- readHTMLTable(tt)[[1]][,1]
head(packageList)
packageList <- readHTMLTable(tt)[[1]][,2]
head(packageList)
packageList <- readHTMLTable(tt)[[1]][,2][c(-1,-2)]
results <- list()
for (pak in packageList) {
#  pak <- "ggplot2"
tt <- readLines(url(paste0("https://cran.r-project.org/src/contrib/Archive/",pak)))
results[[pak]] <- na.omit(data.frame(package=pak,
date=dmy_hm(as.character(readHTMLTable(tt)[[1]][,3]))))
}
pak
which(packageList == "README")
length(packageList == "README")
for (pak in packageList[1620:7302]) {
#  pak <- "ggplot2"
tt <- readLines(url(paste0("https://cran.r-project.org/src/contrib/Archive/",pak)))
results[[pak]] <- na.omit(data.frame(package=pak,
date=dmy_hm(as.character(readHTMLTable(tt)[[1]][,3]))))
}
aa <- scan(what = character())
resultsAA <- list()
for (pak in aa) {
#  pak <- "ggplot2"
tt <- readLines(url(paste0("https://cran.r-project.org/src/contrib/Archive/",pak)))
results[[pak]] <- na.omit(data.frame(package=pak,
date=dmy_hm(as.character(readHTMLTable(tt)[[1]][,3]))))
}
resultsAA <- list()
for (pak in aa) {
#  pak <- "ggplot2"
tt <- readLines(url(paste0("https://cran.r-project.org/src/contrib/Archive/",pak)))
resultsAA[[pak]] <- na.omit(data.frame(package=pak,
date=dmy_hm(as.character(readHTMLTable(tt)[[1]][,3]))))
}
pak
resultsAA <- list()
for (pak in aa) {
#  pak <- "ggplot2"
if (pak != "manipulate") {
tt <- readLines(url(paste0("https://cran.r-project.org/src/contrib/Archive/",pak)))
resultsAA[[pak]] <- na.omit(data.frame(package=pak,
date=dmy_hm(as.character(readHTMLTable(tt)[[1]][,3]))))
}
}
resultsAA
library(ggplot2)
selectedPackages <- do.call(rbind, resultsAA)
head(selectedPackages)
ggplot(selectedPackages, aes(date, package)) +
geom_point()
library(knitr)
library(dplyr)
selectedPackages %>%
group_by(package) %>%
summary(avg = mean(diff(date)))
selectedPackages %>%
group_by(package) %>%
summaries(avg = mean(diff(date)))
selectedPackages %>%
group_by(package) %>%
summarise(avg = mean(diff(date)))
?diff.Date
selectedPackages %>%
group_by(package) %>%
summarise(avg = mean(diff(date,"days" )))
diff.Date
selectedPackages$package <- reorder(selectedPackages$package,
selectedPackages$date,
function(x) diff(range(x))/length(x))
library(ggplot2)
ggplot(selectedPackages, aes(date, package)) +
geom_point()
tt <- readLines(url("https://cran.r-project.org/src/contrib/"))
currentList <- readHTMLTable(tt)[[1]]
head(currentList)
head(currentList,200)
head(currentList[grepl(as.character(currentList[,2]), pattern="gz$"),])
currentList <- currentList[grepl(as.character(currentList[,2]), pattern="gz$"),]
gsub(currentList$Name, pattern = "_.*$", replacement="")
head(currentList)
head(selectedPackages)
currentPackages <- data.frame(package=gsub(currentList$Name, pattern = "_.*$", replacement=""),
date = dmy_hm(as.character(currentList$`Last modified`)))
selectedPackages <- rbind(selectedPackages, currentPackages)
selectedPackages$package <- reorder(selectedPackages$package,
selectedPackages$date,
function(x) diff(range(x))/length(x))
ggplot(selectedPackages, aes(date, package)) +
geom_point()
currentPackages[currentPackages$package %in% aa, ]
selectedPackages <- rbind(selectedPackages, currentPackages[currentPackages$package %in% aa, ])
selectedPackages$package <- reorder(selectedPackages$package,
selectedPackages$date,
function(x) diff(range(x))/length(x))
ggplot(selectedPackages, aes(date, package)) +
geom_point()
selectedPackages <- do.call(rbind, resultsAA)
currentPackages <- data.frame(package=gsub(currentList$Name, pattern = "_.*$", replacement=""),
date = dmy_hm(as.character(currentList$`Last modified`)))
selectedPackages <- rbind(selectedPackages, currentPackages[currentPackages$package %in% aa, ])
library(dplyr)
selectedPackages$package <- reorder(selectedPackages$package,
selectedPackages$date,
function(x) diff(range(x))/length(x))
library(ggplot2)
ggplot(selectedPackages, aes(date, package)) +
geom_point()
selectedPackages$package <- reorder(selectedPackages$package,
selectedPackages$date,
function(x) max(x))
library(ggplot2)
ggplot(selectedPackages, aes(date, package)) +
geom_point()
edit(aa)
library(XML)
library(lubridate)
library(dplyr)
library(ggplot2)
packages <- c("Rcpp", "ggplot2", "stringr", "plyr", "digest", "reshape2",
"colorspace", "RColorBrewer", "manipulate", "scales", "labeling",
"proto", "munsell", "gtable", "dichromat", "mime", "RCurl", "bitops",
"zoo", "knitr")
getCurrentVersions <- fuction(packages) {
tt <- readLines(url("https://cran.r-project.org/src/contrib/"))
currentList <- readHTMLTable(tt)[[1]]
currentList <- currentList[grepl(as.character(currentList[,2]), pattern="gz$"),]
currentPackages <- data.frame(package=gsub(currentList$Name, pattern = "_.*$", replacement=""),
date = dmy_hm(as.character(currentList$`Last modified`)))
currentPackages[currentPackages$package %in% packages,]
}
getOlderVersions <- fuction(packages) {
results <- list()
for (pak in packages) {
tt <- readLines(url(paste0("https://cran.r-project.org/src/contrib/Archive/",pak)))
results[[pak]] <- na.omit(data.frame(package=pak,
date=dmy_hm(as.character(readHTMLTable(tt)[[1]][,3]))))
}
do.call(rbind, results)
}
selectedPackages <- rbind(getOlderVersions(packages),
getCurrentVersions(packages))
selectedPackages$package <- reorder(selectedPackages$package,
selectedPackages$date,
function(x) max(x))
ggplot(selectedPackages, aes(date, package)) +
geom_point()
getCurrentVersions <- fuction(packages) {
tt <- readLines(url("https://cran.r-project.org/src/contrib/"))
currentList <- readHTMLTable(tt)[[1]]
currentList <- currentList[grepl(as.character(currentList[,2]), pattern="gz$"),]
currentPackages <- data.frame(package=gsub(currentList$Name, pattern = "_.*$", replacement=""),
date = dmy_hm(as.character(currentList$`Last modified`)))
currentPackages[currentPackages$package %in% packages,]
}
getCurrentVersions <- function(packages) {
tt <- readLines(url("https://cran.r-project.org/src/contrib/"))
currentList <- readHTMLTable(tt)[[1]]
currentList <- currentList[grepl(as.character(currentList[,2]), pattern="gz$"),]
currentPackages <- data.frame(package=gsub(currentList$Name, pattern = "_.*$", replacement=""),
date = dmy_hm(as.character(currentList$`Last modified`)))
currentPackages[currentPackages$package %in% packages,]
}
getOlderVersions <- function(packages) {
results <- list()
for (pak in packages) {
tt <- readLines(url(paste0("https://cran.r-project.org/src/contrib/Archive/",pak)))
results[[pak]] <- na.omit(data.frame(package=pak,
date=dmy_hm(as.character(readHTMLTable(tt)[[1]][,3]))))
}
do.call(rbind, results)
}
selectedPackages <- rbind(getOlderVersions(packages),
getCurrentVersions(packages))
options(error=recover)
selectedPackages <- rbind(getOlderVersions(packages),
getCurrentVersions(packages))
pak
length(tt)
head(tt)
any(grepl(tt, pattern="Object not found!"))
getOlderVersions <- function(packages) {
results <- list()
for (pak in packages) {
tt <- readLines(url(paste0("https://cran.r-project.org/src/contrib/Archive/",pak)))
if (!any(grepl(tt, pattern="Object not found!"))) {
results[[pak]] <- na.omit(data.frame(package=pak,
date=dmy_hm(as.character(readHTMLTable(tt)[[1]][,3]))))
}
}
do.call(rbind, results)
}
selectedPackages <- rbind(getOlderVersions(packages),
getCurrentVersions(packages))
selectedPackages$package <- reorder(selectedPackages$package,
selectedPackages$date,
function(x) max(x))
ggplot(selectedPackages, aes(date, package)) +
geom_point()
cv <- getCurrentVersions(packages)
ggplot(cv, aes(date, package)) +
stat_ecdf(geom = "step")
ggplot(cv, aes(date)) +
stat_ecdf(geom = "step")
library(lubridate)
archivist::aread('pbiecek/archivist/scripts/packDev/17d11f6af0b7f1a230b2c11d4395a0a9')
log(100,2)
archivist::aread('pbiecek/archivist/scripts/packDev/17d11f6af0b7f1a230b2c11d4395a0a9')
archivist::aread('pbiecek/archivist/scripts/packDev/039745c40ab717f4459c5144343baca1')
archivist::aread('pbiecek/archivist/scripts/packDev/17d11f6af0b7f1a230b2c11d4395a0a9')
archivist::aread('pbiecek/archivist/scripts/packDev/923ec99f79cce099408d4973471dd30d')
asession("pbiecek/archivist/scripts/packDev/923ec99f79cce099408d4973471dd30d")
archivist::asession("pbiecek/archivist/scripts/packDev/923ec99f79cce099408d4973471dd30d")
library(archivist)
archivist::asearch("pbiecek/archivist/scripts/packDev/", patterns = "class:ggplot")
archivist::asearch("pbiecek/archivist/scripts/packDev", patterns = "class:ggplot")
archivist::asearch("pbiecek/archivist", patterns = "class:ggplot")
archivist::asearch("pbiecek/graphGallery", patterns = "class:ggplot")
ll <- archivist::asearch("pbiecek/graphGallery", patterns = "class:ggplot")
length(ll)
aread("pbiecek/graphGallery/600bda83cb840947976bd1ce3a11879d")
load("/Users/pbiecek/GitHub/graphGallery/_old_/gallery/2a6e492cb6982f230e48cf46023e2e4f.rda")
(load("/Users/pbiecek/GitHub/graphGallery/_old_/gallery/2a6e492cb6982f230e48cf46023e2e4f.rda"))
model
setLocalRepo("~/GitHub/graphGallery")
saveToLocalRepo(model)
repo <- "arepo"
invisible(createLocalRepo(repoDir = repo))
copyRemoteRepo( repoTo = repo, md5hashes= "600bda83cb840947976bd1ce3a11879d",
user="pbiecek", repo="graphGallery" )
expect_is(showLocalRepo(repoDir = repo, method = "tags"), "data.frame")
class(showLocalRepo(repoDir = repo, method = "tags"))
dim(showLocalRepo(repoDir = repo, method = "tags"))
searchpaths()
library(archivist)
rmFromRepo()
setLocalRepo("arepo/")
asearch("")
asearch("class:ggplot")
rmFromRepo("600bda83cb840947976bd1ce3a11879d")
setwd("GitHub/Przewodnik/")
require(Rgitbook)
checkForGitbook()
checkForGitbook
str(system("npm", ignore.stdout = TRUE))
str(system("npm"))
system("gitbook", ignore.stdout = TRUE)
?system
system("gitbook", ignore.stdout = TRUE)
system("gitbook")
str(system("gitbook"))
str(system("npm"))
str(system("npm help config"))
str(system("npm"))
library(devtools)
install_github("renkun-ken/Rgitbook")
checkForGitbook()
buildRmd()
